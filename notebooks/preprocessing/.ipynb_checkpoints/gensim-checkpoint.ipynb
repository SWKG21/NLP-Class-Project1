{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>compactification geometry and duality</td>\n",
       "      <td>Paul S. Aspinwall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>these are notes based on lectures given at tas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>2000</td>\n",
       "      <td>domain walls and massive gauged supergravity p...</td>\n",
       "      <td>M. Cvetic, H. Lu, C.N. Pope</td>\n",
       "      <td>Class.Quant.Grav.</td>\n",
       "      <td>we point out that massive gauged supergravity ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>2000</td>\n",
       "      <td>comment on metric fluctuations in brane worlds</td>\n",
       "      <td>Y.S. Myung, Gungwon Kang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>recently ivanov and volovich hep-th 9912242 cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>2000</td>\n",
       "      <td>moving mirrors and thermodynamic paradoxes</td>\n",
       "      <td>Adam D. Helfer</td>\n",
       "      <td>Phys.Rev.</td>\n",
       "      <td>quantum fields responding to moving mirrors ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>2000</td>\n",
       "      <td>bundles of chiral blocks and boundary conditio...</td>\n",
       "      <td>J. Fuchs, C. Schweigert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>proceedings of lie iii clausthal july 1999 var...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title  \\\n",
       "0  1001  2000              compactification geometry and duality   \n",
       "1  1002  2000  domain walls and massive gauged supergravity p...   \n",
       "2  1003  2000     comment on metric fluctuations in brane worlds   \n",
       "3  1004  2000         moving mirrors and thermodynamic paradoxes   \n",
       "4  1005  2000  bundles of chiral blocks and boundary conditio...   \n",
       "\n",
       "                       authors            journal  \\\n",
       "0            Paul S. Aspinwall                NaN   \n",
       "1  M. Cvetic, H. Lu, C.N. Pope  Class.Quant.Grav.   \n",
       "2     Y.S. Myung, Gungwon Kang                NaN   \n",
       "3               Adam D. Helfer          Phys.Rev.   \n",
       "4      J. Fuchs, C. Schweigert                NaN   \n",
       "\n",
       "                                            abstract  \n",
       "0  these are notes based on lectures given at tas...  \n",
       "1  we point out that massive gauged supergravity ...  \n",
       "2  recently ivanov and volovich hep-th 9912242 cl...  \n",
       "3  quantum fields responding to moving mirrors ha...  \n",
       "4  proceedings of lie iii clausthal july 1999 var...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_info = pd.read_csv('../data/node_information.csv', header=None)\n",
    "node_info.columns = ['id', 'year', 'title', 'authors', 'journal', 'abstract']\n",
    "node_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def tokenizer(line):\n",
    "    tokens = [token for token in line.strip().split() if len(token)>1 and token not in STOPWORDS]\n",
    "    tokens = [''.join([elt for elt in token if not elt.isdigit()]) for token in tokens]\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    tokens = [token for token in tokens if len(token)>1 and token not in STOPWORDS]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [tokenizer(node_info.loc[i, 'abstract']) for i in range(len(node_info))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "texts = [[token for token in text if frequency[token]>2] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-11 00:36:12,470 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-03-11 00:36:13,323 : INFO : adding document #10000 to Dictionary(8576 unique tokens: ['benefit', 'tehran', 'post-big', 'travel', 'bremsstrahlung']...)\n",
      "2018-03-11 00:36:14,210 : INFO : adding document #20000 to Dictionary(10040 unique tokens: ['benefit', 'tehran', 'post-big', 'travel', 'bremsstrahlung']...)\n",
      "2018-03-11 00:36:14,714 : INFO : built Dictionary(10313 unique tokens: ['benefit', 'tehran', 'post-big', 'travel', 'bremsstrahlung']...) from 27770 documents (total 1448276 corpus positions)\n",
      "2018-03-11 00:36:14,729 : INFO : discarding 3632 tokens: [('kxt', 3), ('poor', 4), ('maxima', 4), ('ivanov', 4), ('disclin', 4), ('chromofield', 2), ('sin-gordon', 3), ('-soliton', 4), ('vein', 3), (\"manifold'\", 3)]...\n",
      "2018-03-11 00:36:14,730 : INFO : keeping 6681 tokens which were in no less than 5 and no more than 16662 (=60.0%) documents\n",
      "2018-03-11 00:36:14,748 : INFO : resulting dictionary: Dictionary(6681 unique tokens: ['benefit', 'tehran', 'travel', 'bremsstrahlung', 'modifi']...)\n",
      "2018-03-11 00:36:14,750 : INFO : saving Dictionary object under gensim/word2id.dict, separately None\n",
      "2018-03-11 00:36:14,755 : INFO : saved gensim/word2id.dict\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(texts)\n",
    "dictionary.filter_extremes(no_above=0.6, no_below=5)\n",
    "dictionary.save('gensim/word2id.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(6681 unique tokens: ['benefit', 'tehran', 'travel', 'bremsstrahlung', 'modifi']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-11 00:36:16,209 : INFO : collecting document frequencies\n",
      "2018-03-11 00:36:16,212 : INFO : PROGRESS: processing document #0\n",
      "2018-03-11 00:36:16,314 : INFO : PROGRESS: processing document #10000\n",
      "2018-03-11 00:36:16,392 : INFO : PROGRESS: processing document #20000\n",
      "2018-03-11 00:36:16,461 : INFO : calculating IDF weights for 27770 documents and 6680 features (1085999 matrix non-zeros)\n",
      "2018-03-11 00:36:16,465 : INFO : saving TfidfModel object under gensim/model.tfidf, separately None\n",
      "2018-03-11 00:36:16,469 : INFO : saved gensim/model.tfidf\n",
      "2018-03-11 00:36:16,470 : INFO : storing corpus in Matrix Market format to gensim/corpus_tfidf.mm\n",
      "2018-03-11 00:36:16,471 : INFO : saving sparse matrix to gensim/corpus_tfidf.mm\n",
      "2018-03-11 00:36:16,471 : INFO : PROGRESS: saving document #0\n",
      "2018-03-11 00:36:16,624 : INFO : PROGRESS: saving document #1000\n",
      "2018-03-11 00:36:16,806 : INFO : PROGRESS: saving document #2000\n",
      "2018-03-11 00:36:16,946 : INFO : PROGRESS: saving document #3000\n",
      "2018-03-11 00:36:17,081 : INFO : PROGRESS: saving document #4000\n",
      "2018-03-11 00:36:17,219 : INFO : PROGRESS: saving document #5000\n",
      "2018-03-11 00:36:17,360 : INFO : PROGRESS: saving document #6000\n",
      "2018-03-11 00:36:17,506 : INFO : PROGRESS: saving document #7000\n",
      "2018-03-11 00:36:17,650 : INFO : PROGRESS: saving document #8000\n",
      "2018-03-11 00:36:17,791 : INFO : PROGRESS: saving document #9000\n",
      "2018-03-11 00:36:17,932 : INFO : PROGRESS: saving document #10000\n",
      "2018-03-11 00:36:18,081 : INFO : PROGRESS: saving document #11000\n",
      "2018-03-11 00:36:18,212 : INFO : PROGRESS: saving document #12000\n",
      "2018-03-11 00:36:18,336 : INFO : PROGRESS: saving document #13000\n",
      "2018-03-11 00:36:18,460 : INFO : PROGRESS: saving document #14000\n",
      "2018-03-11 00:36:18,590 : INFO : PROGRESS: saving document #15000\n",
      "2018-03-11 00:36:18,728 : INFO : PROGRESS: saving document #16000\n",
      "2018-03-11 00:36:18,861 : INFO : PROGRESS: saving document #17000\n",
      "2018-03-11 00:36:18,990 : INFO : PROGRESS: saving document #18000\n",
      "2018-03-11 00:36:19,125 : INFO : PROGRESS: saving document #19000\n",
      "2018-03-11 00:36:19,255 : INFO : PROGRESS: saving document #20000\n",
      "2018-03-11 00:36:19,381 : INFO : PROGRESS: saving document #21000\n",
      "2018-03-11 00:36:19,511 : INFO : PROGRESS: saving document #22000\n",
      "2018-03-11 00:36:19,642 : INFO : PROGRESS: saving document #23000\n",
      "2018-03-11 00:36:19,774 : INFO : PROGRESS: saving document #24000\n",
      "2018-03-11 00:36:19,913 : INFO : PROGRESS: saving document #25000\n",
      "2018-03-11 00:36:20,047 : INFO : PROGRESS: saving document #26000\n",
      "2018-03-11 00:36:20,191 : INFO : PROGRESS: saving document #27000\n",
      "2018-03-11 00:36:20,294 : INFO : saved 27770x6681 matrix, density=0.585% (1085999/185531370)\n",
      "2018-03-11 00:36:20,295 : INFO : saving MmCorpus index to gensim/corpus_tfidf.mm.index\n"
     ]
    }
   ],
   "source": [
    "tfidf = gensim.models.TfidfModel(corpus, id2word=dictionary)\n",
    "tfidf.save('gensim/model.tfidf')\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "gensim.corpora.MmCorpus.serialize('gensim/corpus_tfidf.mm', corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-11 00:36:20,304 : INFO : using serial LSI version on this node\n",
      "2018-03-11 00:36:20,306 : INFO : updating model with new documents\n",
      "2018-03-11 00:36:21,381 : INFO : preparing a new chunk of documents\n",
      "2018-03-11 00:36:21,575 : INFO : using 100 extra samples and 2 power iterations\n",
      "2018-03-11 00:36:21,576 : INFO : 1st phase: constructing (6681, 4300) action matrix\n",
      "2018-03-11 00:36:29,888 : INFO : orthonormalizing (6681, 4300) action matrix\n",
      "2018-03-11 00:37:55,358 : INFO : 2nd phase: running dense svd on (4300, 20000) matrix\n",
      "2018-03-11 00:40:30,541 : INFO : computing the final decomposition\n",
      "2018-03-11 00:40:30,542 : INFO : keeping 4200 factors (discarding 0.209% of energy spectrum)\n",
      "2018-03-11 00:40:36,564 : INFO : processed documents up to #20000\n",
      "2018-03-11 00:40:36,568 : INFO : topic #0(23.890): 0.157*\"string\" + 0.151*\"model\" + 0.141*\"gaug\" + 0.140*\"field\" + 0.139*\"theori\" + 0.129*\"solut\" + 0.114*\"algebra\" + 0.108*\"quantum\" + 0.103*\"gener\" + 0.102*\"equat\"\n",
      "2018-03-11 00:40:36,569 : INFO : topic #1(12.185): 0.440*\"black\" + 0.424*\"hole\" + -0.261*\"algebra\" + 0.210*\"brane\" + 0.186*\"solut\" + 0.149*\"entropi\" + 0.136*\"horizon\" + 0.130*\"string\" + 0.119*\"cosmolog\" + -0.118*\"oper\"\n",
      "2018-03-11 00:40:36,570 : INFO : topic #2(10.559): -0.388*\"black\" + -0.385*\"hole\" + -0.351*\"algebra\" + 0.272*\"brane\" + 0.153*\"string\" + 0.140*\"d-brane\" + -0.136*\"entropi\" + -0.128*\"quantum\" + -0.108*\"represent\" + 0.103*\"gaug\"\n",
      "2018-03-11 00:40:36,571 : INFO : topic #3(9.772): 0.324*\"string\" + 0.254*\"algebra\" + 0.195*\"d-brane\" + -0.152*\"function\" + 0.148*\"type\" + -0.126*\"renorm\" + 0.119*\"dualiti\" + -0.110*\"effect\" + 0.109*\"supergrav\" + 0.109*\"heterot\"\n",
      "2018-03-11 00:40:36,572 : INFO : topic #4(9.397): 0.510*\"brane\" + 0.281*\"algebra\" + -0.274*\"string\" + 0.235*\"cosmolog\" + 0.213*\"bulk\" + -0.150*\"gaug\" + -0.124*\"hole\" + -0.124*\"noncommut\" + -0.120*\"black\" + 0.117*\"solut\"\n",
      "2018-03-11 00:40:36,980 : INFO : preparing a new chunk of documents\n",
      "2018-03-11 00:40:37,054 : INFO : using 100 extra samples and 2 power iterations\n",
      "2018-03-11 00:40:37,055 : INFO : 1st phase: constructing (6681, 4300) action matrix\n",
      "2018-03-11 00:40:40,065 : INFO : orthonormalizing (6681, 4300) action matrix\n",
      "2018-03-11 00:41:45,384 : INFO : 2nd phase: running dense svd on (4300, 7770) matrix\n",
      "2018-03-11 00:43:39,075 : INFO : computing the final decomposition\n",
      "2018-03-11 00:43:39,076 : INFO : keeping 4200 factors (discarding 0.090% of energy spectrum)\n",
      "2018-03-11 00:43:44,941 : INFO : merging projections: (6681, 4200) + (6681, 4200)\n",
      "2018-03-11 00:50:16,685 : INFO : keeping 4200 factors (discarding 1.502% of energy spectrum)\n",
      "2018-03-11 00:50:28,139 : INFO : processed documents up to #27770\n",
      "2018-03-11 00:50:28,140 : INFO : topic #0(28.213): 0.154*\"string\" + 0.148*\"gaug\" + 0.147*\"theori\" + 0.143*\"model\" + 0.139*\"field\" + 0.124*\"solut\" + 0.104*\"action\" + 0.102*\"quantum\" + 0.101*\"algebra\" + 0.100*\"gener\"\n",
      "2018-03-11 00:50:28,141 : INFO : topic #1(14.192): -0.496*\"black\" + -0.480*\"hole\" + 0.195*\"algebra\" + -0.173*\"entropi\" + -0.169*\"solut\" + -0.164*\"brane\" + -0.135*\"horizon\" + -0.129*\"string\" + -0.108*\"extrem\" + -0.106*\"dilaton\"\n",
      "2018-03-11 00:50:28,143 : INFO : topic #2(12.421): 0.304*\"hole\" + 0.303*\"black\" + -0.290*\"brane\" + 0.253*\"algebra\" + -0.242*\"string\" + -0.219*\"d-brane\" + -0.165*\"type\" + 0.137*\"quantum\" + -0.118*\"supergrav\" + 0.114*\"entropi\"\n",
      "2018-03-11 00:50:28,144 : INFO : topic #3(11.534): -0.387*\"algebra\" + 0.162*\"effect\" + -0.153*\"string\" + -0.128*\"construct\" + -0.125*\"type\" + 0.124*\"temperatur\" + 0.123*\"potenti\" + 0.121*\"renorm\" + 0.120*\"energi\" + -0.117*\"d-brane\"\n",
      "2018-03-11 00:50:28,145 : INFO : topic #4(10.727): 0.434*\"brane\" + 0.307*\"boundari\" + -0.280*\"gaug\" + 0.185*\"cosmolog\" + 0.185*\"algebra\" + 0.184*\"bulk\" + -0.159*\"hole\" + -0.157*\"black\" + -0.120*\"su\" + 0.116*\"condit\"\n",
      "2018-03-11 00:50:28,164 : INFO : saving Projection object under gensim/model_4200.lsi.projection, separately None\n",
      "2018-03-11 00:50:28,166 : INFO : storing np array 'u' to gensim/model_4200.lsi.projection.u.npy\n",
      "2018-03-11 00:50:28,292 : INFO : saved gensim/model_4200.lsi.projection\n",
      "2018-03-11 00:50:28,293 : INFO : saving LsiModel object under gensim/model_4200.lsi, separately None\n",
      "2018-03-11 00:50:28,294 : INFO : not storing attribute projection\n",
      "2018-03-11 00:50:28,295 : INFO : not storing attribute dispatcher\n",
      "2018-03-11 00:50:28,300 : INFO : saved gensim/model_4200.lsi\n"
     ]
    }
   ],
   "source": [
    "lsi = gensim.models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=4200)\n",
    "lsi.save('gensim/model_4200.lsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vecs_tuple = lsi[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows treated\n",
      "2000 rows treated\n",
      "4000 rows treated\n",
      "6000 rows treated\n",
      "8000 rows treated\n",
      "10000 rows treated\n",
      "12000 rows treated\n",
      "14000 rows treated\n",
      "16000 rows treated\n",
      "18000 rows treated\n",
      "20000 rows treated\n",
      "22000 rows treated\n",
      "24000 rows treated\n",
      "26000 rows treated\n"
     ]
    }
   ],
   "source": [
    "num_topics = 4200\n",
    "docs_vec = np.zeros((len(vecs_tuple), num_topics))\n",
    "for r, tuples in enumerate(vecs_tuple):\n",
    "    for t in tuples:\n",
    "        docs_vec[r, t[0]] = t[1]\n",
    "    if r%2000 == 0:\n",
    "        print('{} rows treated'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('gensim/docs_vec.txt', docs_vec, delimiter=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus_tfidf[13456]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "row = []\n",
    "col = []\n",
    "data = []\n",
    "for cnt, doc in enumerate(corpus_tfidf):\n",
    "    row += [cnt for _ in doc]\n",
    "    col += [t[0] for t in doc]\n",
    "    data += [t[1] for t in doc]\n",
    "row = np.array(row)\n",
    "col = np.array(col)\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_matrix = csr_matrix((data, (row, col)), shape=(len(corpus_tfidf), max(col)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_matrix[13456, 9578]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "u, s, v = svds(tfidf_matrix, k=min(tfidf_matrix.shape)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_square = s ** 2\n",
    "s_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_sort = s_square[np.argsort(s_square)[::-1]]\n",
    "s_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_cum = s_sort.cumsum()/sum(s_sort) * 100\n",
    "s_cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_cum[4190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_sort.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('gensim/tmp/s.txt', s, delimiter=' ')\n",
    "np.savetxt('gensim/tmp/s_sort.txt', s_sort, delimiter=' ')\n",
    "np.savetxt('gensim/tmp/s_cum.txt', s_cum, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import save_npz\n",
    "save_npz('gensim/tmp/tfidf_matrix.npz', tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
